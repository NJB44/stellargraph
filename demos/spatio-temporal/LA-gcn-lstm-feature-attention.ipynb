{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forcasting using spatio-temporal data with combined Graph Convolution + LSTM model\n",
    "\n",
    "The dynamics of many real-world phenomena are spatio-temporal in nature. Traffic forecasting is a quintessential example of spatio-temporal problems for which we present here a deep learning framework that models speed prediction using spatio-temporal data. The task is challenging due to two main inter-linked factors: (1) the complex spatial dependency on road networks, and (2) non-linear temporal dynamics with changing road conditions.\n",
    "\n",
    "To address these challenge, here we  explore a neural network architecture that learns from both the spatial road network data and time-series of historical speed changes to forecast speeds on road segments at a future time. We use a 2-layer graph convolution network to leverage the graph structure of the road network. The output of the graph convolution network is fed into an LSTM based sequence to sequence model, that is jointly trained on the output of gcn and the historical speeds of a segment. \n",
    "\n",
    "The architecture of the gcn-lstm model is inpired by the paper: [T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction](https://ieeexplore.ieee.org/document/8809901).\n",
    "\n",
    "The authors have made available the implementation of their model in their github [repo](https://github.com/lehaifeng/T-GCN).\n",
    "There has been a few differences in the architecture proposed in the paper and the implementation with regards to the graph convolution component, these issues have been documented [here](https://github.com/lehaifeng/T-GCN/issues/18) and [here](https://github.com/lehaifeng/T-GCN/issues/14). Here we attempt at emulating the model as explained in the paperr. \n",
    "\n",
    "Concretetly, \n",
    "1. We use the 2-layer graph convolutional network (gcn) proposed by [Kipf & Welling (ICLR 2017)](http://arxiv.org/abs/1609.02907)\n",
    "2. We stack the gcn with 1 layer of LSTM. The [TGCN](https://ieeexplore.ieee.org/document/8809901) uses GRU instead of LSTM. In practice there are not any remarkable differences between the two types of layers. We use LSTM as they are more frequently used.\n",
    "3. We further add a Dropout and Dense layer as they experimentally showed improvement in performance and managing over-fitting.\n",
    "#### References: \n",
    "* [T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction](https://ieeexplore.ieee.org/document/8809901)\n",
    "* [https://github.com/lehaifeng/T-GCN](https://github.com/lehaifeng/T-GCN)\n",
    "* [Semi-Supervised Classification with Graph Convolutional Networks](http://arxiv.org/abs/1609.02907)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "            \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "\n",
    "We apply the gcn-lstm model to the ***Los-loop*** data. This traffic dataset\n",
    "contains traffic information collected from loop detectors in the highway of Los Angeles County (Jagadish\n",
    "et al., 2014).  There are several processed versions of this dataset used by the research community working in Traffic forecasting space. \n",
    "\n",
    "This demo is based on the pre-processed version of the dataset used by the TGCN paper. It can be directly accessed from there [github repo](https://github.com/lehaifeng/T-GCN/tree/master/data). \n",
    "\n",
    "This dataset  contains traffic speeds from Mar.1 to Mar.7, 2012 of 207 sensors, recorded every 5 minutes. \n",
    "\n",
    "In order to use the model, we need:\n",
    "\n",
    "* A N by N adjacency matrix, which describes the spatial relationship between roads,\n",
    "* A N by D feature matrix, which describes the speed change over time on the roads.\n",
    "\n",
    "We have provided the csv files of the weighted adjacency matrix and the time-series of speeds in the [/data](/data) directory with the demo for convenience. However, this may change in near future. The data can still be obtained by the TGCN repo nonetheless. \n",
    "\n",
    "A couple of other references for the same data albeit different time length are as follows: \n",
    "\n",
    "* [DIFFUSION CONVOLUTIONAL RECURRENT NEURAL NETWORK: DATA-DRIVEN TRAFFIC FORECASTING](https://github.com/liyaguang/DCRNN/tree/master/data): This dataset consists of 207 sensors and collect 4 months of data ranging from Mar 1st 2012 to Jun 30th 2012 for the experiment. It has some missing values.\n",
    "* [ST-MetaNet: Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta Learning](https://github.com/panzheyi/ST-MetaNet/tree/master/traffic-prediction). This work uses the DCRNN pre-proccessed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stellargraph as sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'stellargraph' has no attribute 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8b1257fe58cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'stellargraph' has no attribute 'datasets'"
     ]
    }
   ],
   "source": [
    "dataset = sg.datasets.Cora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sg.datasets.Cora()\n",
    "display(HTML(dataset.description))\n",
    "G, node_subjects = dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_data import load_los_data, train_test_split, scale_data, sequence_data_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, adj = load_los_data('los')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = data.shape[1]\n",
    "time_len = data.shape[0]\n",
    "print( \"No. of sensors:\", num_nodes, \"\\nNo of timesteps:\",time_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rate = 0.8\n",
    "train_data, test_data = train_test_split(data, train_rate)\n",
    "print(\"Train data: \", train_data.shape)\n",
    "print(\"Test data: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, test_scaled = scale_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence data perparation for LSTM\n",
    "\n",
    "* Each training observation are 10 historical speeds.\n",
    "*Each training prediction is the speed 30 minutes later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 10\n",
    "pre_len = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY = sequence_data_preparation(seq_len, pre_len, train_scaled, test_scaled)\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StellarGraph Graph Convolution and LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.layer import Graph_Convolution_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_lstm_model = Graph_Convolution_LSTM(num_nodes, adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_lstm_model.compile(optimizer = \"adam\", loss = 'mae', metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gcn_lstm_model.fit(trainX,trainY,epochs = 200, batch_size = 60, verbose = 0, validation_data = [testX,testY])\n",
    "print(\"Train loss: \", history.history['loss'][-1], \"\\nTest loss:\", history.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label = 'Training loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Test loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ythat = gcn_lstm_model.predict(trainX)\n",
    "yhat = gcn_lstm_model.predict(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rescale values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rescale values\n",
    "max_speed = train_data.max()\n",
    "min_speed = train_data.min()\n",
    "\n",
    "## actual train and test values\n",
    "train_rescref=np.array(trainY*max_speed)\n",
    "test_rescref=np.array(testY*max_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rescale model predicted values\n",
    "train_rescpred=np.array((ythat)*max_speed)\n",
    "test_rescpred=np.array((yhat)*max_speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring the performance of the model\n",
    "\n",
    "To understand how well the model is performing, we compare it against a naive benchmark.\n",
    "\n",
    "1. Naive prediction: using the most recently ***observed*** value as the predicted value. Note, that albeit being ***naive*** this is a very strong baseline to beat. Especially, when speeds are recorded at a 5 minutes granularity,  one does not expect many drastic changes within such a short period of time. Hence, for short-term predictions naive is a reasonable good guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive prediction benchmark (using latest observed value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive prediction benchmark (using previous observed value)\n",
    "\n",
    "testnpred=np.array(testX).transpose(1,0,2)[-1] #picking the last speed of the 10 sequence for each segment in each sample\n",
    "testnpredc=(testnpred)*max_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance measures\n",
    "\n",
    "seg_mael=[]\n",
    "seg_masel=[]\n",
    "seg_nmael=[]\n",
    "\n",
    "for j in range(testX.shape[-1]):\n",
    "    \n",
    "    seg_mael.append(np.mean(np.abs(test_rescref.T[j]-test_rescpred.T[j]))) #Mean Absolute Error for NN\n",
    "    seg_nmael.append(np.mean(np.abs(test_rescref.T[j]-testnpredc.T[j]))) #Mean Absolute Error for naive prediction\n",
    "    if seg_nmael[-1] != 0:\n",
    "        seg_masel.append(seg_mael[-1]/seg_nmael[-1]) #Ratio of the two: Mean Absolute Scaled Error\n",
    "    else:\n",
    "        seg_masel.append(np.NaN)\n",
    "        \n",
    "print('Total (ave) MAE for NN: '+str(np.mean(np.array(seg_mael))))\n",
    "print('Total (ave) MAE for naive prediction: '+str(np.mean(np.array(seg_nmael))))\n",
    "print('Total (ave) MASE for per-segment NN/naive MAE: '+str(np.nanmean(np.array(seg_masel))))\n",
    "print('...note that MASE<1 (for a given segment) means that the NN prediction is better than the naive prediction.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot violin plot of MAE for naive and NN predictions\n",
    "fig, ax = plt.subplots()\n",
    "#xl = minsl\n",
    "\n",
    "ax.violinplot(list(seg_mael),\n",
    "                   showmeans=True,\n",
    "                   showmedians=False,\n",
    "              showextrema=False,\n",
    "             widths=1.0)\n",
    "\n",
    "ax.violinplot(list(seg_nmael),\n",
    "                   showmeans=True,\n",
    "                   showmedians=False,\n",
    "              showextrema=False,\n",
    "             widths=1.0)\n",
    "\n",
    "line1 = mlines.Line2D([], [], label='NN')\n",
    "line2 = mlines.Line2D([], [],color='C1', label='Instantaneous')\n",
    "\n",
    "ax.set_xlabel('Scaled distribution amplitude (after Gaussian convolution)')\n",
    "ax.set_ylabel('Mean Absolute Error')\n",
    "ax.set_title('Distribution over segments: NN pred (blue) and naive pred (orange)')\n",
    "plt.legend(handles=(line1,line2),title='Prediction Model',loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_rescref[:200,100])\n",
    "plt.plot(test_rescpred[:200,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##all test result visualization\n",
    "fig1 = plt.figure(figsize=(15,8))\n",
    "#    ax1 = fig1.add_subplot(1,1,1)\n",
    "a_pred = test_rescpred[:,1]\n",
    "a_true = test_rescref[:,1]\n",
    "plt.plot(a_pred,'r-',label='prediction')\n",
    "plt.plot(a_true,'b-',label='true')\n",
    "plt.legend(loc='best',fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
